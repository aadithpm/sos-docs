{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SoS Docker Guide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General introduction\n",
    "\n",
    "### What is docker and why it is helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a big question to answer but in essence you can think docker containers as virtual machines with applications but without the bulky OS part, or applications with stripped down OSes. Docker containers are much more lightweight than virtual machines because all docker containers share the same core OS and related containers (e.g. different applications derived from the same CentOS or Ubuntu OS) share the same base container. Please refer to the [docker website](https://www.docker.com/) for details about docker. I have found it helpful to watch a few youtube videos on docker.\n",
    "\n",
    "The reason why docker is very helpful in building (bioinformatics) workflows are that \n",
    "\n",
    "1. Applications are encapsulated in docker containers so that they do not interfere with the underlying OS, and with other applications. For example, we can run a workflow with applications that based on different versions of Python2 and Python 3 without having to install them locally and calling the correct version of Python, because all applications use the specific version of Python and required libraries and tools inside their own containers.\n",
    "\n",
    "2. Workflows will be more stable and reproducible because unlike, for example, a local installation of Python that can be affected by other software and upgrades of python, Docker containers are stable and will not change.\n",
    "\n",
    "3. The same docker containers can be executed on different OS (e.g. various version of Linux, MacOSX etc) so your workflow built on a Mac OS workstation can be executed on a cluster environment.\n",
    "\n",
    "There are of course some complexity in the use of docker but SoS has made it extremely easy to use docker in your workflows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing and configuring docker\n",
    "\n",
    "Docker is relatively new and is evolving very fast. It is crucial for you to install the latest version from [docker website](https://www.docker.com/). This website provides very detailed step by step instruction and you should have no problem installing docker on your machine. \n",
    "\n",
    "After installation, you should be able to start a docker terminal and run command\n",
    "\n",
    "```bash\n",
    "$ docker run hello-world\n",
    "```\n",
    "\n",
    "as suggested by the documentation. Depending on the different versions of docker (e.g. docker under windows), docker might be run under a virtual machine. It is very important to understand that **the configuration (e.g. RAM, CPU) of docker machines are different from the host machines** so your docker machine might be restricuted to, for example, 1 CPU, 1G of RAM, which is insufficient for any serious work. You will most likely need to re-configure your docker virtual machine (e.g. from VirtualBox app locate a machine named `default`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a script inside docker\n",
    "\n",
    "Running a docker-based workflow is easy because SoS will automatically download docker images and execute scripts inside docker container. Anyway, before you start any workflow running docker, it is a good idea to check if your docker daemon is running by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID        IMAGE               COMMAND               CREATED             STATUS              PORTS                   NAMES\n",
      "3a8fec17646e        eg_sshd             \"/usr/sbin/sshd -D\"   3 days ago          Up 3 days           0.0.0.0:32768->22/tcp   test_sos\n"
     ]
    }
   ],
   "source": [
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How SoS works with docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you do not have ruby installed locally and would like to run a ruby script, you can execute it inside a `ruby` container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "SoS",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line1 contains Cats\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "%run\n",
    "ruby: docker_image='ruby'\n",
    "    line1 = \"Cats are smarter than dogs\";\n",
    "    line2 = \"Dogs also like meat\";\n",
    "\n",
    "    if ( line1 =~ /Cats(.*)/ )\n",
    "      puts \"Line1 contains Cats\"\n",
    "    end\n",
    "    if ( line2 =~ /Cats(.*)/ )\n",
    "      puts \"Line2 contains  Dogs\"\n",
    "    end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the script with option `-v3`, you would see a line showing the actual `docker run` command executed by SoS. The command would look similar to\n",
    "\n",
    "```\n",
    "docker run --rm   -v /Users:/Users -v /tmp:/tmp \n",
    "    -v /tmp/path/to/docker_run_30258.rb:/var/lib/sos/docker_run_30258.rb\n",
    "    -t -P \n",
    "    -w=/Users/bpeng1/sos/sos-docs/src/tutorials\n",
    "    -u 12345:54321    ruby\n",
    "    ruby /var/lib/sos/docker_run_30258.rb\n",
    "```\n",
    "\n",
    "Basically, SoS downloads a docker image called `ruby` and runs command `docker run` to execte the specified script, with the following options\n",
    "\n",
    "* `--rm` Automatically remove the container when it exits\n",
    "* `-v /Users:/Users` `-v /tmp:/tmp` maps local directories `/Users` and `/tmp` to the docker image so that these directories can be accessed from within the docker image.\n",
    "* `-v /tmp/path/to/docker_run_30258.rb:/var/lib/sos/docker_run_30258.rb` maps a temporary script (`/Users/bpeng1/sos/sos-docs/src/tutorials/tmp2zviq3qh/docker_run_30258.rb` to the docker image.\n",
    "* `-t` Allocate a pseudo-tty\n",
    "* `-P` Publish all exposed ports to the host interfaces\n",
    "* `-w=/Users/bpeng1/sos/sos-docs/src/tutorials` Set working directory to current working directory\n",
    "* `-u 12345:54321` Use the host user-id and group-id inside docker so that files created by docker (on shared volumes) could be accessible from outside of docker.\n",
    "* `ruby` name of the docker image\n",
    "* `ruby` name of the interpreter for the script\n",
    "* `/var/lib/sos/docker_run_30258.rb` the script inside of docker\n",
    "\n",
    "The details of these options could be found at the [docker run manual](https://docs.docker.com/engine/reference/run/). They are chosen by the default to work with a majority of the scenarios but can fail for some docker images, in which case you will need to use SoS action parameters to customized the way the images are executed. These parameters include general [action parameters](https://vatlab.github.io/sos-docs/doc/documentation/Targets_and_Actions.html#Action-options-12) and [parameters that are specific to `docker_image`](https://vatlab.github.io/sos-docs/doc/documentation/Targets_and_Actions.html#docker_image)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building docker-image on-the-fly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a docker image is usually done outside of SoS if you are maintaining a collection of docker containers to be shared by your workflows, your groups, or everyone. However, if you need to create a docker image on-the-fly or would like to embed the Dockerfile inside a SoS script, you can use the `docker_build` action to build a docker container.\n",
    "\n",
    "For example, you can build simple image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docker_build: tag='test_docker'\n",
    "  FROM ubuntu:14.04\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and use the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "kernel": "SoS",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin  games  include  lib  local  sbin  share  src\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "sh: docker_image='test_docker'\n",
    "  ls /usr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will build a series of simple docker images to demonstrate the use of various options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized or image-default working directory (`workdir` and `docker_workdir`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SoS by default sets the current working directory of the docker image to the working directory of the host system, essentially adding `-w $(pwd)` to the command line. For example, with the following docker image, the `pwd` of the script is the current working directory on the host machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bpeng1/sos/sos-docs/src/tutorials\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "sh: docker_image='ubuntu:14.04'\n",
    "  echo `pwd`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the action option `workdir` can change the working directory of the script, you can use this option to change the script of the working directory of the docker image as well. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bpeng1/sos/sos-docs/src\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "sh: docker_image='ubuntu:14.04', workdir='..'\n",
    "  echo `pwd`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This default behavior is convenient when you use commands in a docker machine to process input files on your host machine but it has a few caveats:\n",
    "\n",
    "1. The current working directory might not be accessible to the docker image.\n",
    "2. The docker machine might have its own `WORKDIR` for the command to work.\n",
    "3. You might want to specify another working directory inside of docker.\n",
    "\n",
    "The first problem is solved by SoS' attemp to map current working directory to the docker image and will be discussed in the next section. The second and third problem can be addressed by another option `docker_workdir`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Option `docker_workdir`, if specified, overrides `workdir` and allows the use of default or customized working directory inside of docker image. When `docker_workdir` is set to `None`, no `-w` option will be passed to the docker image and the default `WORKDIR` will be used. Otherwise an absolute path inside the docker image can be specified.\n",
    "\n",
    "For example, the following customized docker image has a `WORKDIR` set to `/usr`. It is working directory is set to host working directory by default, to `/usr` with `docker_workdir=None`, and `/home/random_user` with `docker_workdir='/home/random_user'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bpeng1/sos/sos-docs/src/tutorials\n",
      "/usr\n",
      "/home/random_user\n"
     ]
    }
   ],
   "source": [
    "docker_build: tag='test_docker_workdir'\n",
    "  FROM ubuntu:14.04\n",
    "  WORKDIR /usr\n",
    "\n",
    "sh: docker_image='test_docker_workdir'\n",
    "  echo `pwd`\n",
    "  \n",
    "sh: docker_image='test_docker_workdir', docker_workdir=None\n",
    "  echo `pwd`\n",
    "  \n",
    "sh: docker_image='test_docker_workdir', docker_workdir='/home/random_user'\n",
    "  echo `pwd`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the directory is relative to the docker file system so it does not have to exist on the host system. Docker also creates the `docker_workdir` if it does not exist so you do not have to create the directory in advance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sharing of input and output files (`volumes`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the working directory of the docker image is set by default to the current working directory, you can apply a command inside a docker image to files in the current working directory, and create files on it as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "sh: docker_image='ubuntu:14.04'\n",
    "  wc -l SoS_Docker_Guide.ipynb > docker_wc.txt\n",
    "  \n",
    "sh:\n",
    "  cat docker_wc.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works because SoS automatically shares the home directory  (`/Users` for mac and `/home` for Linux) and current working directory (if not under `$HOME`) of the host system to the docker image. Because the docker image can only \"see\" file systems shared by command `docker run`, your script will fail in the following scenarios:\n",
    "\n",
    "* Your input files or output files are on a separate file system (not under `/home` and `$(pwd)`.\n",
    "* You cannot share home or current working directory to docker image because of possible side effects.\n",
    "\n",
    "For example, if your script writes something to a mobile harddrive, the script could execute successfully on the host system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sh:\n",
    "  wc -l SoS_Docker_Guide.ipynb > /Volumes/Mobile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but fail in a docker image because the image cannot see the `/Volumes` file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/lib/sos/docker_run_39643.sh: 1: /var/lib/sos/docker_run_39643.sh: cannot create /Volumes/Mobile: Directory nonexistent\r",
      "\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing script in docker returns an error (exitcode=2).\n",
      "The script has been saved to /Users/bpeng1/sos/sos-docs/src/tutorials/.sos/docker_run_39643.sh. To reproduce the error please run:\n",
      "``docker run --rm   -v /Users:/Users -v /tmp:/tmp -v /Users/bpeng1/sos/sos-docs/src/tutorials/.sos/docker_run_39643.sh:/var/lib/sos/docker_run_39643.sh    -t -P -w=/Users/bpeng1/sos/sos-docs/src/tutorials -u 1985961928:895809667    ubuntu:14.04 /bin/sh /var/lib/sos/docker_run_39643.sh``\n"
     ]
    }
   ],
   "source": [
    "sh: docker_image='ubuntu:14.04'\n",
    "  wc -l SoS_Docker_Guide.ipynb > /Volumes/Mobile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem could be solved by specifying `/Volumes` in option `volumes`. This parameter\n",
    "\n",
    "1. By default maps `/Users` to `/Users` (mac), `/home` to `/home`.\n",
    "2. If specified, share only user-specified file systems. In this case you can specify different path names from host and docker file systems (e.g. `/Users:/home`)\n",
    "\n",
    "Current working directory is always mapped if it is not under default or specified directories.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<strong>Note:</strong>\n",
    "If docker is implemented as a virtual machine, the file systems that are available to docker will be limited by the shared file systems of the virtual machine. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if you would like to read input files from or write output files to another file system, you can add it to option `volumes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1236 SoS_Docker_Guide.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "sh: docker_image='ubuntu:14.04', volumes='/Volumes'\n",
    "  wc -l SoS_Docker_Guide.ipynb > /Volumes/Mobile\n",
    "\n",
    "sh:\n",
    "  cat /Volumes/Mobile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case SoS only shared `/Volumes` to `/Volumes` and `$(PWD)` (current working directory) to `$(PWD)`. `$HOME` is no longer shared, which can be a good thing because sharing of home directory to docker host can cause unexpected conflicts between docker and host systems. For example, your `.R` directory, when mapped to a docker image, might change the behavior of the `R` command inside docker.\n",
    "\n",
    "Finally, if you have to share your home directory to the docker image but do not want to expose your host settings to the image, you can map your local volumes under different names. For example, the following script maps current working directory as `/input` and destination directory as `/output` to the docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1249 /input/sos/sos-docs/src/tutorials/SoS_Docker_Guide.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "sh: docker_image='ubuntu:14.04', volumes=['~:/input', '/Volumes:/output']\n",
    "  wc -l /input/sos/sos-docs/src/tutorials/SoS_Docker_Guide.ipynb > /output/Mobile\n",
    "\n",
    "sh:\n",
    "  cat /Volumes/Mobile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customize user and group ID (`user`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO: explain uid and gid. Use of `--user uid` and `--user uid:gid`.\n",
    "Use `--user None` to stop sending host uid/gid to docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_build: tag='test_docker_workdir'\n",
    "  FROM ubuntu:14.04\n",
    "  USER /blah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker images with `entry_point`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some docker image has an `entry_point` which determines the command that will be executed when the image is executed. If we run the script directly, our \"command\" (e.g. `ruby /var/lib/sos/docker_run_30258.rb` will be appended to the `entry_point` and will not be executed properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, docker image [`dceoy/gatk`](https://hub.docker.com/r/dceoy/gatk/~/dockerfile/) has an entry point\n",
    "\n",
    "```\n",
    "[\"java\", \"-jar\", \"/usr/local/src/gatk/build/libs/gatk.jar\"]\n",
    "```\n",
    "\n",
    "and does not accept any additional interpreter. What we really need to do is to append \"arguments\" to this pre-specified command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that action `script` does not have a default interpreter, and option `args` can be used to construct a command line, we can use this docker image in the format of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: docker pull dceoy/gatk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mUSAGE:  \u001b[32m<program name>\u001b[1m\u001b[31m [-h]\n",
      "\n",
      "\u001b[0m\u001b[1m\u001b[31mAvailable Programs:\n",
      "\u001b[0m\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mBase Calling:                                    Tools that process sequencing machine data, e.g. Illumina base calls, and detect sequencing level attributes, e.g. adapters\u001b[0m\n",
      "\u001b[32m    CheckIlluminaDirectory (Picard)              \u001b[36mAsserts the validity for specified Illumina basecalling data.  \u001b[0m\n",
      "\u001b[32m    CollectIlluminaBasecallingMetrics (Picard)   \u001b[36mCollects Illumina Basecalling metrics for a sequencing run.  \u001b[0m\n",
      "\u001b[32m    CollectIlluminaLaneMetrics (Picard)          \u001b[36mCollects Illumina lane metrics for the given BaseCalling analysis directory.  \u001b[0m\n",
      "\u001b[32m    ExtractIlluminaBarcodes (Picard)             \u001b[36mTool determines the barcode for each read in an Illumina lane.  \u001b[0m\n",
      "\u001b[32m    IlluminaBasecallsToFastq (Picard)            \u001b[36mGenerate FASTQ file(s) from Illumina basecall read data.  \u001b[0m\n",
      "\u001b[32m    IlluminaBasecallsToSam (Picard)              \u001b[36mTransforms raw Illumina sequencing data into an unmapped SAM or BAM file.\u001b[0m\n",
      "\u001b[32m    MarkIlluminaAdapters (Picard)                \u001b[36mReads a SAM or BAM file and rewrites it with new adapter-trimming tags.  \u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mCopy Number Variant Discovery:                   Tools that analyze read coverage to detect copy number variants.\u001b[0m\n",
      "\u001b[32m    AnnotateIntervals                            \u001b[31m(BETA Tool) \u001b[36mAnnotates intervals with GC content\u001b[0m\n",
      "\u001b[32m    CallCopyRatioSegments                        \u001b[31m(BETA Tool) \u001b[36mCalls copy-ratio segments as amplified, deleted, or copy-number neutral\u001b[0m\n",
      "\u001b[32m    CombineSegmentBreakpoints                    \u001b[31m(EXPERIMENTAL Tool) \u001b[36mCombine the breakpoints of two segment files and annotate the resulting intervals with chosen columns from each file.\u001b[0m\n",
      "\u001b[32m    CreateReadCountPanelOfNormals                \u001b[31m(BETA Tool) \u001b[36mCreates a panel of normals for read-count denoising\u001b[0m\n",
      "\u001b[32m    DenoiseReadCounts                            \u001b[31m(BETA Tool) \u001b[36mDenoises read counts to produce denoised copy ratios\u001b[0m\n",
      "\u001b[32m    DetermineGermlineContigPloidy                \u001b[31m(BETA Tool) \u001b[36mDetermines the baseline contig ploidy for germline samples given counts data\u001b[0m\n",
      "\u001b[32m    GermlineCNVCaller                            \u001b[31m(BETA Tool) \u001b[36mCalls copy-number variants in germline samples given their counts and the output of DetermineGermlineContigPloidy\u001b[0m\n",
      "\u001b[32m    ModelSegments                                \u001b[31m(BETA Tool) \u001b[36mModels segmented copy ratios from denoised read counts and segmented minor-allele fractions from allelic counts\u001b[0m\n",
      "\u001b[32m    PlotDenoisedCopyRatios                       \u001b[31m(BETA Tool) \u001b[36mCreates plots of denoised copy ratios\u001b[0m\n",
      "\u001b[32m    PlotModeledSegments                          \u001b[31m(BETA Tool) \u001b[36mCreates plots of denoised and segmented copy-ratio and minor-allele-fraction estimates\u001b[0m\n",
      "\u001b[32m    PostprocessGermlineCNVCalls                  \u001b[36mCreate a VCF given the output of GermlineCNVCaller.\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mCoverage Analysis:                               Tools that count coverage, e.g. depth per allele\u001b[0m\n",
      "\u001b[32m    ASEReadCounter                               \u001b[36mGenerates table of filtered base counts at het sites for allele specific expression\u001b[0m\n",
      "\u001b[32m    CollectAllelicCounts                         \u001b[31m(BETA Tool) \u001b[36mCollects reference and alternate allele counts at specified sites\u001b[0m\n",
      "\u001b[32m    CollectFragmentCounts                        \u001b[31m(BETA Tool) \u001b[36mCollects fragment counts at specified intervals\u001b[0m\n",
      "\u001b[32m    CountBases                                   \u001b[36mCount bases in a SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    CountBasesSpark                              \u001b[31m(BETA Tool) \u001b[36mCounts bases in the input SAM/BAM\u001b[0m\n",
      "\u001b[32m    CountReads                                   \u001b[36mCount reads in a SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    CountReadsSpark                              \u001b[31m(BETA Tool) \u001b[36mCounts reads in the input SAM/BAM\u001b[0m\n",
      "\u001b[32m    GetPileupSummaries                           \u001b[31m(BETA Tool) \u001b[36mTabulates pileup metrics for inferring contamination\u001b[0m\n",
      "\u001b[32m    Pileup                                       \u001b[36mPrints read alignments in samtools pileup format\u001b[0m\n",
      "\u001b[32m    PileupSpark                                  \u001b[31m(BETA Tool) \u001b[36mPrints read alignments in samtools pileup format\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mDiagnostics and Quality Control:                 Tools that collect sequencing quality related and comparative metrics\u001b[0m\n",
      "\u001b[32m    AccumulateVariantCallingMetrics (Picard)     \u001b[36mCombines multiple Variant Calling Metrics files into a single file\u001b[0m\n",
      "\u001b[32m    AnalyzeCovariates                            \u001b[36mEvaluate and compare base quality score recalibration (BQSR) tables\u001b[0m\n",
      "\u001b[32m    BamIndexStats (Picard)                       \u001b[36mGenerate index statistics from a BAM file\u001b[0m\n",
      "\u001b[32m    CalcMetadataSpark                            \u001b[31m(BETA Tool) \u001b[36m(Internal) Collects read metrics relevant to structural variant discovery\u001b[0m\n",
      "\u001b[32m    CalculateContamination                       \u001b[36mCalculate the fraction of reads coming from cross-sample contamination\u001b[0m\n",
      "\u001b[32m    CalculateReadGroupChecksum (Picard)          \u001b[36mCreates a hash code based on the read groups (RG).  \u001b[0m\n",
      "\u001b[32m    CheckFingerprint (Picard)                    \u001b[36mComputes a fingerprint from the supplied input (SAM/BAM or VCF) file and compares it to the provided genotypes\u001b[0m\n",
      "\u001b[32m    CheckPileup                                  \u001b[36mCompare GATK's internal pileup to a reference Samtools mpileup\u001b[0m\n",
      "\u001b[32m    CheckTerminatorBlock (Picard)                \u001b[36mAsserts the provided gzip file's (e.g., BAM) last block is well-formed; RC 100 otherwise\u001b[0m\n",
      "\u001b[32m    ClusterCrosscheckMetrics (Picard)            \u001b[36mClusters the results of a CrosscheckFingerprints run by LOD score\u001b[0m\n",
      "\u001b[32m    CollectAlignmentSummaryMetrics (Picard)      \u001b[36m<b>Produces a summary of alignment metrics from a SAM or BAM file.</b>  \u001b[0m\n",
      "\u001b[32m    CollectBaseDistributionByCycle (Picard)      \u001b[36mChart the nucleotide distribution per cycle in a SAM or BAM file\u001b[0m\n",
      "\u001b[32m    CollectBaseDistributionByCycleSpark          \u001b[31m(BETA Tool) \u001b[36mCollects base distribution per cycle in SAM/BAM/CRAM file(s).\u001b[0m\n",
      "\u001b[32m    CollectGcBiasMetrics (Picard)                \u001b[36mCollect metrics regarding GC bias. \u001b[0m\n",
      "\u001b[32m    CollectHiSeqXPfFailMetrics (Picard)          \u001b[36mClassify PF-Failing reads in a HiSeqX Illumina Basecalling directory into various categories.\u001b[0m\n",
      "\u001b[32m    CollectHsMetrics (Picard)                    \u001b[36mCollects hybrid-selection (HS) metrics for a SAM or BAM file.  \u001b[0m\n",
      "\u001b[32m    CollectIndependentReplicateMetrics (Picard)  \u001b[31m(BETA Tool) \u001b[36m(Experimental) Estimates the rate of independent replication of reads within a bam.\u001b[0m\n",
      "\u001b[32m    CollectInsertSizeMetrics (Picard)            \u001b[36mCollect metrics about the insert size distribution of a paired-end library.\u001b[0m\n",
      "\u001b[32m    CollectInsertSizeMetricsSpark                \u001b[31m(BETA Tool) \u001b[36mCollects insert size distribution information on alignment data\u001b[0m\n",
      "\u001b[32m    CollectJumpingLibraryMetrics (Picard)        \u001b[36mCollect jumping library metrics. \u001b[0m\n",
      "\u001b[32m    CollectMultipleMetrics (Picard)              \u001b[36mCollect multiple classes of metrics.  \u001b[0m\n",
      "\u001b[32m    CollectMultipleMetricsSpark                  \u001b[31m(BETA Tool) \u001b[36mRuns multiple metrics collection modules for a given alignment file\u001b[0m\n",
      "\u001b[32m    CollectOxoGMetrics (Picard)                  \u001b[36mCollect metrics to assess oxidative artifacts.\u001b[0m\n",
      "\u001b[32m    CollectQualityYieldMetrics (Picard)          \u001b[36mCollect metrics about reads that pass quality thresholds and Illumina-specific filters.  \u001b[0m\n",
      "\u001b[32m    CollectQualityYieldMetricsSpark              \u001b[31m(BETA Tool) \u001b[36mCollects quality yield metrics from SAM/BAM/CRAM file(s).\u001b[0m\n",
      "\u001b[32m    CollectRawWgsMetrics (Picard)                \u001b[36mCollect whole genome sequencing-related metrics.  \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m    CollectRnaSeqMetrics (Picard)                \u001b[36mProduces RNA alignment metrics for a SAM or BAM file.  \u001b[0m\n",
      "\u001b[32m    CollectRrbsMetrics (Picard)                  \u001b[36m<b>Collects metrics from reduced representation bisulfite sequencing (Rrbs) data.</b>  \u001b[0m\n",
      "\u001b[32m    CollectSequencingArtifactMetrics (Picard)    \u001b[36mCollect metrics to quantify single-base sequencing artifacts.  \u001b[0m\n",
      "\u001b[32m    CollectTargetedPcrMetrics (Picard)           \u001b[36mCalculate PCR-related metrics from targeted sequencing data. \u001b[0m\n",
      "\u001b[32m    CollectVariantCallingMetrics (Picard)        \u001b[36mCollects per-sample and aggregate (spanning all samples) metrics from the provided VCF file\u001b[0m\n",
      "\u001b[32m    CollectWgsMetrics (Picard)                   \u001b[36mCollect metrics about coverage and performance of whole genome sequencing (WGS) experiments.\u001b[0m\n",
      "\u001b[32m    CollectWgsMetricsWithNonZeroCoverage (Picard)\u001b[31m(BETA Tool) \u001b[36m(Experimental) Collect metrics about coverage and performance of whole genome sequencing (WGS) experiments.  \u001b[0m\n",
      "\u001b[32m    CompareBaseQualities                         \u001b[36mCompares the base qualities of two SAM/BAM/CRAM files\u001b[0m\n",
      "\u001b[32m    CompareDuplicatesSpark                       \u001b[31m(BETA Tool) \u001b[36mDetermine if two potentially identical BAMs have the same duplicate reads\u001b[0m\n",
      "\u001b[32m    CompareMetrics (Picard)                      \u001b[36mCompare two metrics files.\u001b[0m\n",
      "\u001b[32m    CompareSAMs (Picard)                         \u001b[36mCompare two input \".sam\" or \".bam\" files.  \u001b[0m\n",
      "\u001b[32m    ConvertSequencingArtifactToOxoG (Picard)     \u001b[36mExtract OxoG metrics from generalized artifacts metrics.  \u001b[0m\n",
      "\u001b[32m    CrosscheckFingerprints (Picard)              \u001b[36mChecks that all data in the input files appear to have come from the same individual\u001b[0m\n",
      "\u001b[32m    CrosscheckReadGroupFingerprints (Picard)     \u001b[36mDEPRECATED: USE CrosscheckFingerprints. Checks if all read groups appear to come from the same individual.\u001b[0m\n",
      "\u001b[32m    EstimateLibraryComplexity (Picard)           \u001b[36mEstimates the numbers of unique molecules in a sequencing library.  \u001b[0m\n",
      "\u001b[32m    EstimateLibraryComplexityGATK                \u001b[31m(BETA Tool) \u001b[36mEstimate library complexity from the sequence of read pairs\u001b[0m\n",
      "\u001b[32m    FlagStat                                     \u001b[36mAccumulate flag statistics given a BAM file\u001b[0m\n",
      "\u001b[32m    FlagStatSpark                                \u001b[31m(BETA Tool) \u001b[36mSpark tool to accumulate flag statistics\u001b[0m\n",
      "\u001b[32m    GetSampleName                                \u001b[31m(BETA Tool) \u001b[36mEmit a single sample name\u001b[0m\n",
      "\u001b[32m    MeanQualityByCycle (Picard)                  \u001b[36mCollect mean quality by cycle.\u001b[0m\n",
      "\u001b[32m    MeanQualityByCycleSpark                      \u001b[31m(BETA Tool) \u001b[36mMeanQualityByCycle on Spark\u001b[0m\n",
      "\u001b[32m    QualityScoreDistribution (Picard)            \u001b[36mChart the distribution of quality scores.  \u001b[0m\n",
      "\u001b[32m    QualityScoreDistributionSpark                \u001b[31m(BETA Tool) \u001b[36mQualityScoreDistribution on Spark\u001b[0m\n",
      "\u001b[32m    ValidateSamFile (Picard)                     \u001b[36mValidates a SAM or BAM file.\u001b[0m\n",
      "\u001b[32m    ViewSam (Picard)                             \u001b[36mPrints a SAM or BAM file to the screen\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mIntervals Manipulation:                          Tools that process genomic intervals in various formats\u001b[0m\n",
      "\u001b[32m    BedToIntervalList (Picard)                   \u001b[36mConverts a BED file to a Picard Interval List.  \u001b[0m\n",
      "\u001b[32m    IntervalListToBed (Picard)                   \u001b[36mConverts an Picard IntervalList file to a BED file.\u001b[0m\n",
      "\u001b[32m    IntervalListTools (Picard)                   \u001b[36mA tool for performing various IntervalList manipulations\u001b[0m\n",
      "\u001b[32m    LiftOverIntervalList (Picard)                \u001b[36mLifts over an interval list from one reference build to another. \u001b[0m\n",
      "\u001b[32m    PreprocessIntervals                          \u001b[31m(BETA Tool) \u001b[36mPrepares bins for coverage collection\u001b[0m\n",
      "\u001b[32m    SplitIntervals                               \u001b[36mSplit intervals into sub-interval files.\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mMetagenomics:                                    Tools that perform metagenomic analysis, e.g. microbial community composition and pathogen detection\u001b[0m\n",
      "\u001b[32m    PathSeqBuildKmers                            \u001b[36mBuilds set of host reference k-mers\u001b[0m\n",
      "\u001b[32m    PathSeqBuildReferenceTaxonomy                \u001b[36mBuilds a taxonomy datafile of the microbe reference\u001b[0m\n",
      "\u001b[32m    PathSeqBwaSpark                              \u001b[36mStep 2: Aligns reads to the microbe reference\u001b[0m\n",
      "\u001b[32m    PathSeqFilterSpark                           \u001b[36mStep 1: Filters low quality, low complexity, duplicate, and host reads\u001b[0m\n",
      "\u001b[32m    PathSeqPipelineSpark                         \u001b[36mCombined tool that performs all steps: read filtering, microbe reference alignment, and abundance scoring\u001b[0m\n",
      "\u001b[32m    PathSeqScoreSpark                            \u001b[36mStep 3: Classifies pathogen-aligned reads and generates abundance scores\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mOther:                                           Miscellaneous tools, e.g. those that aid in data streaming\u001b[0m\n",
      "\u001b[32m    CreateHadoopBamSplittingIndex                \u001b[31m(BETA Tool) \u001b[36mCreate a Hadoop BAM splitting index\u001b[0m\n",
      "\u001b[32m    FifoBuffer (Picard)                          \u001b[36mProvides a large, FIFO buffer that can be used to buffer input and output streams between programs.\u001b[0m\n",
      "\u001b[32m    GatherBQSRReports                            \u001b[36mGathers scattered BQSR recalibration reports into a single file\u001b[0m\n",
      "\u001b[32m    GatherTranches                               \u001b[31m(BETA Tool) \u001b[36mGathers scattered VQSLOD tranches into a single file\u001b[0m\n",
      "\u001b[32m    IndexFeatureFile                             \u001b[36mCreates an index for a feature file, e.g. VCF or BED file.\u001b[0m\n",
      "\u001b[32m    ParallelCopyGCSDirectoryIntoHDFSSpark        \u001b[31m(BETA Tool) \u001b[36mParallel copy a file or directory from Google Cloud Storage into the HDFS file system used by Spark\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mRead Data Manipulation:                          Tools that manipulate read data in SAM, BAM or CRAM format\u001b[0m\n",
      "\u001b[32m    AddCommentsToBam (Picard)                    \u001b[36mAdds comments to the header of a BAM file.\u001b[0m\n",
      "\u001b[32m    AddOrReplaceReadGroups (Picard)              \u001b[36mAssigns all the reads in a file to a single new read-group.\u001b[0m\n",
      "\u001b[32m    ApplyBQSR                                    \u001b[36mApply base quality score recalibration\u001b[0m\n",
      "\u001b[32m    ApplyBQSRSpark                               \u001b[31m(BETA Tool) \u001b[36mApply base quality score recalibration on Spark\u001b[0m\n",
      "\u001b[32m    BQSRPipelineSpark                            \u001b[31m(BETA Tool) \u001b[36mBoth steps of BQSR (BaseRecalibrator and ApplyBQSR) on Spark\u001b[0m\n",
      "\u001b[32m    BamToBfq (Picard)                            \u001b[36mConverts a BAM file into a BFQ (binary fastq formatted) file\u001b[0m\n",
      "\u001b[32m    BaseRecalibrator                             \u001b[36mGenerates recalibration table for Base Quality Score Recalibration (BQSR)\u001b[0m\n",
      "\u001b[32m    BaseRecalibratorSpark                        \u001b[31m(BETA Tool) \u001b[36mGenerate recalibration table for Base Quality Score Recalibration (BQSR) on Spark\u001b[0m\n",
      "\u001b[32m    BaseRecalibratorSparkSharded                 \u001b[31m(EXPERIMENTAL Tool) \u001b[36mBaseRecalibrator on Spark (experimental sharded implementation)\u001b[0m\n",
      "\u001b[32m    BuildBamIndex (Picard)                       \u001b[36mGenerates a BAM index \".bai\" file.  \u001b[0m\n",
      "\u001b[32m    BwaAndMarkDuplicatesPipelineSpark            \u001b[31m(BETA Tool) \u001b[36mTakes name-sorted file and runs BWA and MarkDuplicates.\u001b[0m\n",
      "\u001b[32m    BwaSpark                                     \u001b[31m(BETA Tool) \u001b[36mBWA on Spark\u001b[0m\n",
      "\u001b[32m    CleanSam (Picard)                            \u001b[36mCleans the provided SAM/BAM, soft-clipping beyond-end-of-reference alignments and setting MAPQ to 0 for unmapped reads\u001b[0m\n",
      "\u001b[32m    ClipReads                                    \u001b[36mClip reads in a SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    ConvertHeaderlessHadoopBamShardToBam         \u001b[31m(BETA Tool) \u001b[36mConvert a headerless BAM shard into a readable BAM\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m    DownsampleSam (Picard)                       \u001b[36mDownsample a SAM or BAM file.\u001b[0m\n",
      "\u001b[32m    ExtractOriginalAlignmentRecordsByNameSpark   \u001b[31m(BETA Tool) \u001b[36mSubsets reads by name\u001b[0m\n",
      "\u001b[32m    FastqToSam (Picard)                          \u001b[36mConverts a FASTQ file to an unaligned BAM or SAM file\u001b[0m\n",
      "\u001b[32m    FilterSamReads (Picard)                      \u001b[36mSubsets reads from a SAM or BAM file by applying one of several filters.\u001b[0m\n",
      "\u001b[32m    FixMateInformation (Picard)                  \u001b[36mVerify mate-pair information between mates and fix if needed.\u001b[0m\n",
      "\u001b[32m    FixMisencodedBaseQualityReads                \u001b[36mFix Illumina base quality scores in a SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    GatherBamFiles (Picard)                      \u001b[36mConcatenate efficiently BAM files that resulted from a scattered parallel analysis\u001b[0m\n",
      "\u001b[32m    LeftAlignIndels                              \u001b[36mLeft-aligns indels from reads in a SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    MarkDuplicates (Picard)                      \u001b[36mIdentifies duplicate reads.  \u001b[0m\n",
      "\u001b[32m    MarkDuplicatesGATK                           \u001b[31m(EXPERIMENTAL Tool) \u001b[36mExamines aligned records in the supplied SAM/BAM/CRAM file to locate duplicate molecules.\u001b[0m\n",
      "\u001b[32m    MarkDuplicatesSpark                          \u001b[31m(BETA Tool) \u001b[36mMarkDuplicates on Spark\u001b[0m\n",
      "\u001b[32m    MarkDuplicatesWithMateCigar (Picard)         \u001b[36mIdentifies duplicate reads, accounting for mate CIGAR.  \u001b[0m\n",
      "\u001b[32m    MergeBamAlignment (Picard)                   \u001b[36mMerge alignment data from a SAM or BAM with data in an unmapped BAM file.  \u001b[0m\n",
      "\u001b[32m    MergeSamFiles (Picard)                       \u001b[36mMerges multiple SAM and/or BAM files into a single file.  \u001b[0m\n",
      "\u001b[32m    PositionBasedDownsampleSam (Picard)          \u001b[36mDownsample a SAM or BAM file to retain a subset of the reads based on the reads location in each tile in the flowcell.\u001b[0m\n",
      "\u001b[32m    PrintReads                                   \u001b[36mPrint reads in the SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    PrintReadsSpark                              \u001b[31m(BETA Tool) \u001b[36mPrintReads on Spark\u001b[0m\n",
      "\u001b[32m    ReorderSam (Picard)                          \u001b[36mReorders reads in a SAM or BAM file to match ordering in a second reference file.\u001b[0m\n",
      "\u001b[32m    ReplaceSamHeader (Picard)                    \u001b[36mReplaces the SAMFileHeader in a SAM or BAM file.  \u001b[0m\n",
      "\u001b[32m    RevertBaseQualityScores                      \u001b[36mRevert Quality Scores in a SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    RevertOriginalBaseQualitiesAndAddMateCigar (Picard)\u001b[36mReverts the original base qualities and adds the mate cigar tag to read-group BAMs\u001b[0m\n",
      "\u001b[32m    RevertSam (Picard)                           \u001b[36mReverts SAM or BAM files to a previous state.  \u001b[0m\n",
      "\u001b[32m    SamFormatConverter (Picard)                  \u001b[36mConvert a BAM file to a SAM file, or a SAM to a BAM\u001b[0m\n",
      "\u001b[32m    SamToFastq (Picard)                          \u001b[36mConverts a SAM or BAM file to FASTQ.\u001b[0m\n",
      "\u001b[32m    SetNmAndUqTags (Picard)                      \u001b[36mDEPRECATED: Use SetNmMdAndUqTags instead.\u001b[0m\n",
      "\u001b[32m    SetNmMdAndUqTags (Picard)                    \u001b[36mFixes the NM, MD, and UQ tags in a SAM file \u001b[0m\n",
      "\u001b[32m    SimpleMarkDuplicatesWithMateCigar (Picard)   \u001b[31m(BETA Tool) \u001b[36m(Experimental) Examines aligned records in the supplied SAM or BAM file to locate duplicate molecules.\u001b[0m\n",
      "\u001b[32m    SortSam (Picard)                             \u001b[36mSorts a SAM or BAM file\u001b[0m\n",
      "\u001b[32m    SortSamSpark                                 \u001b[31m(BETA Tool) \u001b[36mSortSam on Spark (works on SAM/BAM/CRAM)\u001b[0m\n",
      "\u001b[32m    SplitNCigarReads                             \u001b[36mSplit Reads with N in Cigar\u001b[0m\n",
      "\u001b[32m    SplitReads                                   \u001b[36mOutputs reads from a SAM/BAM/CRAM by read group, sample and library name\u001b[0m\n",
      "\u001b[32m    SplitSamByLibrary (Picard)                   \u001b[36mSplits a SAM or BAM file into individual files by library\u001b[0m\n",
      "\u001b[32m    SplitSamByNumberOfReads (Picard)             \u001b[36mSplits a SAM or BAM file to multiple BAMs.\u001b[0m\n",
      "\u001b[32m    UmiAwareMarkDuplicatesWithMateCigar (Picard) \u001b[31m(BETA Tool) \u001b[36mIdentifies duplicate reads using information from read positions and UMIs. \u001b[0m\n",
      "\u001b[32m    UnmarkDuplicates                             \u001b[36mClears the 0x400 duplicate SAM flag\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mReference:                                       Tools that analyze and manipulate FASTA format references\u001b[0m\n",
      "\u001b[32m    BaitDesigner (Picard)                        \u001b[36mDesigns oligonucleotide baits for hybrid selection reactions.\u001b[0m\n",
      "\u001b[32m    BwaMemIndexImageCreator                      \u001b[36mCreate a BWA-MEM index image file for use with GATK BWA tools\u001b[0m\n",
      "\u001b[32m    CreateSequenceDictionary (Picard)            \u001b[36mCreates a sequence dictionary for a reference sequence.  \u001b[0m\n",
      "\u001b[32m    ExtractSequences (Picard)                    \u001b[36mSubsets intervals from a reference sequence to a new FASTA file.\u001b[0m\n",
      "\u001b[32m    FindBadGenomicKmersSpark                     \u001b[31m(BETA Tool) \u001b[36mIdentifies sequences that occur at high frequency in a reference\u001b[0m\n",
      "\u001b[32m    NonNFastaSize (Picard)                       \u001b[36mCounts the number of non-N bases in a fasta file.\u001b[0m\n",
      "\u001b[32m    NormalizeFasta (Picard)                      \u001b[36mNormalizes lines of sequence in a FASTA file to be of the same length.\u001b[0m\n",
      "\u001b[32m    ScatterIntervalsByNs (Picard)                \u001b[36mWrites an interval list created by splitting a reference at Ns.\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mShort Variant Discovery:                         Tools that perform variant calling and genotyping for short variants (SNPs, SNVs and Indels)\u001b[0m\n",
      "\u001b[32m    CombineGVCFs                                 \u001b[36mMerges one or more HaplotypeCaller GVCF files into a single GVCF with appropriate annotations\u001b[0m\n",
      "\u001b[32m    GenomicsDBImport                             \u001b[36mImport VCFs to GenomicsDB\u001b[0m\n",
      "\u001b[32m    GenotypeGVCFs                                \u001b[36mPerform joint genotyping on one or more samples pre-called with HaplotypeCaller\u001b[0m\n",
      "\u001b[32m    HaplotypeCaller                              \u001b[36mCall germline SNPs and indels via local re-assembly of haplotypes\u001b[0m\n",
      "\u001b[32m    HaplotypeCallerSpark                         \u001b[31m(BETA Tool) \u001b[36mHaplotypeCaller on Spark\u001b[0m\n",
      "\u001b[32m    Mutect2                                      \u001b[36mCall somatic SNVs and indels via local assembly of haplotypes\u001b[0m\n",
      "\u001b[32m    ReadsPipelineSpark                           \u001b[31m(BETA Tool) \u001b[36mTakes unaligned or aligned reads and runs BWA (if specified), MarkDuplicates, BQSR, and HaplotypeCaller to generate a VCF file of variants\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mStructural Variant Discovery:                    Tools that detect structural variants        \u001b[0m\n",
      "\u001b[32m    DiscoverVariantsFromContigAlignmentsSAMSpark \u001b[31m(BETA Tool) \u001b[36m(Internal) Examines aligned contigs from local assemblies and calls structural variants\u001b[0m\n",
      "\u001b[32m    ExtractSVEvidenceSpark                       \u001b[31m(BETA Tool) \u001b[36m(Internal) Extracts evidence of structural variations from reads\u001b[0m\n",
      "\u001b[32m    FindBreakpointEvidenceSpark                  \u001b[31m(BETA Tool) \u001b[36m(Internal) Produces local assemblies of genomic regions that may harbor structural variants\u001b[0m\n",
      "\u001b[32m    StructuralVariationDiscoveryPipelineSpark    \u001b[31m(BETA Tool) \u001b[36mRuns the structural variation discovery workflow on a single sample\u001b[0m\n",
      "\u001b[32m    SvDiscoverFromLocalAssemblyContigAlignmentsSpark    \u001b[31m(BETA Tool) \u001b[36m(Internal) Examines aligned contigs from local assemblies and calls structural variants or their breakpoints\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mVariant Evaluation and Refinement:               Tools that evaluate and refine variant calls, e.g. with annotations not offered by the engine\u001b[0m\n",
      "\u001b[32m    AnnotatePairOrientation                      \u001b[31m(BETA Tool) \u001b[36m(EXPERIMENTAL) Annotate a non-M2 VCF (using the associated tumor bam) with pair orientation fields (e.g. F1R2 ).\u001b[0m\n",
      "\u001b[32m    AnnotateVcfWithBamDepth                      \u001b[36m(Internal) Annotate a vcf with a bam's read depth at each variant locus\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m    AnnotateVcfWithExpectedAlleleFraction        \u001b[36m(Internal) Annotate a vcf with expected allele fractions in pooled sequencing\u001b[0m\n",
      "\u001b[32m    CalculateGenotypePosteriors                  \u001b[36mCalculate genotype posterior probabilities given family and/or known population genotypes\u001b[0m\n",
      "\u001b[32m    CalculateMixingFractions                     \u001b[36m(Internal) Calculate proportions of different samples in a pooled bam\u001b[0m\n",
      "\u001b[32m    Concordance                                  \u001b[31m(BETA Tool) \u001b[36mEvaluate concordance of an input VCF against a validated truth VCF\u001b[0m\n",
      "\u001b[32m    CountFalsePositives                          \u001b[31m(BETA Tool) \u001b[36mCount PASS variants\u001b[0m\n",
      "\u001b[32m    CountVariants                                \u001b[36mCounts variant records in a VCF file, regardless of filter status.\u001b[0m\n",
      "\u001b[32m    CountVariantsSpark                           \u001b[31m(BETA Tool) \u001b[36mCountVariants on Spark\u001b[0m\n",
      "\u001b[32m    FindMendelianViolations (Picard)             \u001b[36mFinds mendelian violations of all types within a VCF\u001b[0m\n",
      "\u001b[32m    Funcotator                                   \u001b[31m(BETA Tool) \u001b[36mFunctional Annotator\u001b[0m\n",
      "\u001b[32m    GenotypeConcordance (Picard)                 \u001b[36mCalculates the concordance between genotype data of one samples in each of two VCFs - one  being considered the truth (or reference) the other being the call.  The concordance is broken into separate results sections for SNPs and indels.  Statistics are reported in three different files.\u001b[0m\n",
      "\u001b[32m    NeuralNetInference                           \u001b[31m(EXPERIMENTAL Tool) \u001b[36mApply 1d Convolutional Neural Net to filter annotated variants\u001b[0m\n",
      "\u001b[32m    ValidateBasicSomaticShortMutations           \u001b[31m(EXPERIMENTAL Tool) \u001b[36mCheck the variants in a VCF against a tumor-normal pair of bams representing the same samples, though not the ones from the actual calls.\u001b[0m\n",
      "\u001b[32m    ValidateVariants                             \u001b[36mValidate VCF\u001b[0m\n",
      "\u001b[32m    VariantsToTable                              \u001b[36mExtract fields from a VCF file to a tab-delimited table\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mVariant Filtering:                               Tools that filter variants by annotating the FILTER column\u001b[0m\n",
      "\u001b[32m    ApplyVQSR                                    \u001b[36m Apply a score cutoff to filter variants based on a recalibration table\u001b[0m\n",
      "\u001b[32m    CreateSomaticPanelOfNormals                  \u001b[31m(BETA Tool) \u001b[36mMake a panel of normals for use with Mutect2\u001b[0m\n",
      "\u001b[32m    FilterByOrientationBias                      \u001b[31m(EXPERIMENTAL Tool) \u001b[36mFilter Mutect2 somatic variant calls using orientation bias\u001b[0m\n",
      "\u001b[32m    FilterMutectCalls                            \u001b[36mFilter somatic SNVs and indels called by Mutect2\u001b[0m\n",
      "\u001b[32m    FilterVcf (Picard)                           \u001b[36mHard filters a VCF.\u001b[0m\n",
      "\u001b[32m    VariantFiltration                            \u001b[36mFilter variant calls based on INFO and/or FORMAT annotations\u001b[0m\n",
      "\u001b[32m    VariantRecalibrator                          \u001b[36mBuild a recalibration model to score variant quality for filtering purposes\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mVariant Manipulation:                            Tools that manipulate variant call format (VCF) data\u001b[0m\n",
      "\u001b[32m    FixVcfHeader (Picard)                        \u001b[36mReplaces or fixes a VCF header.\u001b[0m\n",
      "\u001b[32m    GatherVcfs (Picard)                          \u001b[36mGathers multiple VCF files from a scatter operation into a single VCF file\u001b[0m\n",
      "\u001b[32m    GatherVcfsCloud                              \u001b[31m(BETA Tool) \u001b[36mGathers multiple VCF files from a scatter operation into a single VCF file\u001b[0m\n",
      "\u001b[32m    LiftoverVcf (Picard)                         \u001b[36mLifts over a VCF file from one reference build to another.  \u001b[0m\n",
      "\u001b[32m    MakeSitesOnlyVcf (Picard)                    \u001b[36mCreates a VCF that contains all the site-level information for all records in the input VCF but no genotype information.\u001b[0m\n",
      "\u001b[32m    MergeVcfs (Picard)                           \u001b[36mCombines multiple variant files into a single variant file\u001b[0m\n",
      "\u001b[32m    PrintVariantsSpark                           \u001b[31m(BETA Tool) \u001b[36mPrints out variants from the input VCF.\u001b[0m\n",
      "\u001b[32m    RemoveNearbyIndels                           \u001b[36m(Internal) Remove indels from the VCF file that are close to each other.\u001b[0m\n",
      "\u001b[32m    RenameSampleInVcf (Picard)                   \u001b[36mRenames a sample within a VCF or BCF.\u001b[0m\n",
      "\u001b[32m    SelectVariants                               \u001b[36mSelect a subset of variants from a VCF file\u001b[0m\n",
      "\u001b[32m    SortVcf (Picard)                             \u001b[36mSorts one or more VCF files.  \u001b[0m\n",
      "\u001b[32m    SplitVcfs (Picard)                           \u001b[36mSplits SNPs and INDELs into separate files.  \u001b[0m\n",
      "\u001b[32m    UpdateVCFSequenceDictionary                  \u001b[36mUpdates the sequence dictionary in a variant file.\u001b[0m\n",
      "\u001b[32m    UpdateVcfSequenceDictionary (Picard)         \u001b[36mTakes a VCF and a second file that contains a sequence dictionary and updates the VCF with the new sequence dictionary.\u001b[0m\n",
      "\u001b[32m    VariantAnnotator                             \u001b[31m(BETA Tool) \u001b[36mTool for adding annotations to VCF files\u001b[0m\n",
      "\u001b[32m    VcfFormatConverter (Picard)                  \u001b[36mConverts VCF to BCF or BCF to VCF.  \u001b[0m\n",
      "\u001b[32m    VcfToIntervalList (Picard)                   \u001b[36mConverts a VCF or BCF file to a Picard Interval List\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\n",
      "***********************************************************************\n",
      "\n",
      "A USER ERROR has occurred: 'Print' is not a valid command.\n",
      "Did you mean one of these?\n",
      "        PrintReads        PrintVariantsSpark        PrintReadsSpark\n",
      "\n",
      "***********************************************************************\n",
      "Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing script in docker returns an error (exitcode=2).\n",
      "The script has been saved to /Users/bpeng1/sos/sos-docs/src/tutorials/.sos/docker_run_30258.sh. To reproduce the error please run:\n",
      "``docker run --rm   -v /Users:/Users -v /tmp:/tmp -v /Users/bpeng1/sos/sos-docs/src/tutorials/.sos/docker_run_30258.sh:/var/lib/sos/docker_run_30258.sh    -t -P -w=/Users/bpeng1/sos/sos-docs/src/tutorials -u 1985961928:895809667    dceoy/gatk  Print Reads -h``\n"
     ]
    }
   ],
   "source": [
    "script: args = 'Print Reads -h', docker_image = 'dceoy/gatk'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which essentially passes `Print Reads -h` to the image and executes command \n",
    "```\n",
    "java -jar /usr/local/src/gatk/build/libs/gatk.jar Print Reads -h\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the command line is long, you can use another trick, that is to say, to use `{script}` in `args` for scripts of the action. For example, the aforementioned command can be specified as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31mUSAGE:  \u001b[32m<program name>\u001b[1m\u001b[31m [-h]\n",
      "\n",
      "\u001b[0m\u001b[1m\u001b[31mAvailable Programs:\n",
      "\u001b[0m\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mBase Calling:                                    Tools that process sequencing machine data, e.g. Illumina base calls, and detect sequencing level attributes, e.g. adapters\u001b[0m\n",
      "\u001b[32m    CheckIlluminaDirectory (Picard)              \u001b[36mAsserts the validity for specified Illumina basecalling data.  \u001b[0m\n",
      "\u001b[32m    CollectIlluminaBasecallingMetrics (Picard)   \u001b[36mCollects Illumina Basecalling metrics for a sequencing run.  \u001b[0m\n",
      "\u001b[32m    CollectIlluminaLaneMetrics (Picard)          \u001b[36mCollects Illumina lane metrics for the given BaseCalling analysis directory.  \u001b[0m\n",
      "\u001b[32m    ExtractIlluminaBarcodes (Picard)             \u001b[36mTool determines the barcode for each read in an Illumina lane.  \u001b[0m\n",
      "\u001b[32m    IlluminaBasecallsToFastq (Picard)            \u001b[36mGenerate FASTQ file(s) from Illumina basecall read data.  \u001b[0m\n",
      "\u001b[32m    IlluminaBasecallsToSam (Picard)              \u001b[36mTransforms raw Illumina sequencing data into an unmapped SAM or BAM file.\u001b[0m\n",
      "\u001b[32m    MarkIlluminaAdapters (Picard)                \u001b[36mReads a SAM or BAM file and rewrites it with new adapter-trimming tags.  \u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mCopy Number Variant Discovery:                   Tools that analyze read coverage to detect copy number variants.\u001b[0m\n",
      "\u001b[32m    AnnotateIntervals                            \u001b[31m(BETA Tool) \u001b[36mAnnotates intervals with GC content\u001b[0m\n",
      "\u001b[32m    CallCopyRatioSegments                        \u001b[31m(BETA Tool) \u001b[36mCalls copy-ratio segments as amplified, deleted, or copy-number neutral\u001b[0m\n",
      "\u001b[32m    CombineSegmentBreakpoints                    \u001b[31m(EXPERIMENTAL Tool) \u001b[36mCombine the breakpoints of two segment files and annotate the resulting intervals with chosen columns from each file.\u001b[0m\n",
      "\u001b[32m    CreateReadCountPanelOfNormals                \u001b[31m(BETA Tool) \u001b[36mCreates a panel of normals for read-count denoising\u001b[0m\n",
      "\u001b[32m    DenoiseReadCounts                            \u001b[31m(BETA Tool) \u001b[36mDenoises read counts to produce denoised copy ratios\u001b[0m\n",
      "\u001b[32m    DetermineGermlineContigPloidy                \u001b[31m(BETA Tool) \u001b[36mDetermines the baseline contig ploidy for germline samples given counts data\u001b[0m\n",
      "\u001b[32m    GermlineCNVCaller                            \u001b[31m(BETA Tool) \u001b[36mCalls copy-number variants in germline samples given their counts and the output of DetermineGermlineContigPloidy\u001b[0m\n",
      "\u001b[32m    ModelSegments                                \u001b[31m(BETA Tool) \u001b[36mModels segmented copy ratios from denoised read counts and segmented minor-allele fractions from allelic counts\u001b[0m\n",
      "\u001b[32m    PlotDenoisedCopyRatios                       \u001b[31m(BETA Tool) \u001b[36mCreates plots of denoised copy ratios\u001b[0m\n",
      "\u001b[32m    PlotModeledSegments                          \u001b[31m(BETA Tool) \u001b[36mCreates plots of denoised and segmented copy-ratio and minor-allele-fraction estimates\u001b[0m\n",
      "\u001b[32m    PostprocessGermlineCNVCalls                  \u001b[36mCreate a VCF given the output of GermlineCNVCaller.\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mCoverage Analysis:                               Tools that count coverage, e.g. depth per allele\u001b[0m\n",
      "\u001b[32m    ASEReadCounter                               \u001b[36mGenerates table of filtered base counts at het sites for allele specific expression\u001b[0m\n",
      "\u001b[32m    CollectAllelicCounts                         \u001b[31m(BETA Tool) \u001b[36mCollects reference and alternate allele counts at specified sites\u001b[0m\n",
      "\u001b[32m    CollectFragmentCounts                        \u001b[31m(BETA Tool) \u001b[36mCollects fragment counts at specified intervals\u001b[0m\n",
      "\u001b[32m    CountBases                                   \u001b[36mCount bases in a SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    CountBasesSpark                              \u001b[31m(BETA Tool) \u001b[36mCounts bases in the input SAM/BAM\u001b[0m\n",
      "\u001b[32m    CountReads                                   \u001b[36mCount reads in a SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    CountReadsSpark                              \u001b[31m(BETA Tool) \u001b[36mCounts reads in the input SAM/BAM\u001b[0m\n",
      "\u001b[32m    GetPileupSummaries                           \u001b[31m(BETA Tool) \u001b[36mTabulates pileup metrics for inferring contamination\u001b[0m\n",
      "\u001b[32m    Pileup                                       \u001b[36mPrints read alignments in samtools pileup format\u001b[0m\n",
      "\u001b[32m    PileupSpark                                  \u001b[31m(BETA Tool) \u001b[36mPrints read alignments in samtools pileup format\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mDiagnostics and Quality Control:                 Tools that collect sequencing quality related and comparative metrics\u001b[0m\n",
      "\u001b[32m    AccumulateVariantCallingMetrics (Picard)     \u001b[36mCombines multiple Variant Calling Metrics files into a single file\u001b[0m\n",
      "\u001b[32m    AnalyzeCovariates                            \u001b[36mEvaluate and compare base quality score recalibration (BQSR) tables\u001b[0m\n",
      "\u001b[32m    BamIndexStats (Picard)                       \u001b[36mGenerate index statistics from a BAM file\u001b[0m\n",
      "\u001b[32m    CalcMetadataSpark                            \u001b[31m(BETA Tool) \u001b[36m(Internal) Collects read metrics relevant to structural variant discovery\u001b[0m\n",
      "\u001b[32m    CalculateContamination                       \u001b[36mCalculate the fraction of reads coming from cross-sample contamination\u001b[0m\n",
      "\u001b[32m    CalculateReadGroupChecksum (Picard)          \u001b[36mCreates a hash code based on the read groups (RG).  \u001b[0m\n",
      "\u001b[32m    CheckFingerprint (Picard)                    \u001b[36mComputes a fingerprint from the supplied input (SAM/BAM or VCF) file and compares it to the provided genotypes\u001b[0m\n",
      "\u001b[32m    CheckPileup                                  \u001b[36mCompare GATK's internal pileup to a reference Samtools mpileup\u001b[0m\n",
      "\u001b[32m    CheckTerminatorBlock (Picard)                \u001b[36mAsserts the provided gzip file's (e.g., BAM) last block is well-formed; RC 100 otherwise\u001b[0m\n",
      "\u001b[32m    ClusterCrosscheckMetrics (Picard)            \u001b[36mClusters the results of a CrosscheckFingerprints run by LOD score\u001b[0m\n",
      "\u001b[32m    CollectAlignmentSummaryMetrics (Picard)      \u001b[36m<b>Produces a summary of alignment metrics from a SAM or BAM file.</b>  \u001b[0m\n",
      "\u001b[32m    CollectBaseDistributionByCycle (Picard)      \u001b[36mChart the nucleotide distribution per cycle in a SAM or BAM file\u001b[0m\n",
      "\u001b[32m    CollectBaseDistributionByCycleSpark          \u001b[31m(BETA Tool) \u001b[36mCollects base distribution per cycle in SAM/BAM/CRAM file(s).\u001b[0m\n",
      "\u001b[32m    CollectGcBiasMetrics (Picard)                \u001b[36mCollect metrics regarding GC bias. \u001b[0m\n",
      "\u001b[32m    CollectHiSeqXPfFailMetrics (Picard)          \u001b[36mClassify PF-Failing reads in a HiSeqX Illumina Basecalling directory into various categories.\u001b[0m\n",
      "\u001b[32m    CollectHsMetrics (Picard)                    \u001b[36mCollects hybrid-selection (HS) metrics for a SAM or BAM file.  \u001b[0m\n",
      "\u001b[32m    CollectIndependentReplicateMetrics (Picard)  \u001b[31m(BETA Tool) \u001b[36m(Experimental) Estimates the rate of independent replication of reads within a bam.\u001b[0m\n",
      "\u001b[32m    CollectInsertSizeMetrics (Picard)            \u001b[36mCollect metrics about the insert size distribution of a paired-end library.\u001b[0m\n",
      "\u001b[32m    CollectInsertSizeMetricsSpark                \u001b[31m(BETA Tool) \u001b[36mCollects insert size distribution information on alignment data\u001b[0m\n",
      "\u001b[32m    CollectJumpingLibraryMetrics (Picard)        \u001b[36mCollect jumping library metrics. \u001b[0m\n",
      "\u001b[32m    CollectMultipleMetrics (Picard)              \u001b[36mCollect multiple classes of metrics.  \u001b[0m\n",
      "\u001b[32m    CollectMultipleMetricsSpark                  \u001b[31m(BETA Tool) \u001b[36mRuns multiple metrics collection modules for a given alignment file\u001b[0m\n",
      "\u001b[32m    CollectOxoGMetrics (Picard)                  \u001b[36mCollect metrics to assess oxidative artifacts.\u001b[0m\n",
      "\u001b[32m    CollectQualityYieldMetrics (Picard)          \u001b[36mCollect metrics about reads that pass quality thresholds and Illumina-specific filters.  \u001b[0m\n",
      "\u001b[32m    CollectQualityYieldMetricsSpark              \u001b[31m(BETA Tool) \u001b[36mCollects quality yield metrics from SAM/BAM/CRAM file(s).\u001b[0m\n",
      "\u001b[32m    CollectRawWgsMetrics (Picard)                \u001b[36mCollect whole genome sequencing-related metrics.  \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m    CollectRnaSeqMetrics (Picard)                \u001b[36mProduces RNA alignment metrics for a SAM or BAM file.  \u001b[0m\n",
      "\u001b[32m    CollectRrbsMetrics (Picard)                  \u001b[36m<b>Collects metrics from reduced representation bisulfite sequencing (Rrbs) data.</b>  \u001b[0m\n",
      "\u001b[32m    CollectSequencingArtifactMetrics (Picard)    \u001b[36mCollect metrics to quantify single-base sequencing artifacts.  \u001b[0m\n",
      "\u001b[32m    CollectTargetedPcrMetrics (Picard)           \u001b[36mCalculate PCR-related metrics from targeted sequencing data. \u001b[0m\n",
      "\u001b[32m    CollectVariantCallingMetrics (Picard)        \u001b[36mCollects per-sample and aggregate (spanning all samples) metrics from the provided VCF file\u001b[0m\n",
      "\u001b[32m    CollectWgsMetrics (Picard)                   \u001b[36mCollect metrics about coverage and performance of whole genome sequencing (WGS) experiments.\u001b[0m\n",
      "\u001b[32m    CollectWgsMetricsWithNonZeroCoverage (Picard)\u001b[31m(BETA Tool) \u001b[36m(Experimental) Collect metrics about coverage and performance of whole genome sequencing (WGS) experiments.  \u001b[0m\n",
      "\u001b[32m    CompareBaseQualities                         \u001b[36mCompares the base qualities of two SAM/BAM/CRAM files\u001b[0m\n",
      "\u001b[32m    CompareDuplicatesSpark                       \u001b[31m(BETA Tool) \u001b[36mDetermine if two potentially identical BAMs have the same duplicate reads\u001b[0m\n",
      "\u001b[32m    CompareMetrics (Picard)                      \u001b[36mCompare two metrics files.\u001b[0m\n",
      "\u001b[32m    CompareSAMs (Picard)                         \u001b[36mCompare two input \".sam\" or \".bam\" files.  \u001b[0m\n",
      "\u001b[32m    ConvertSequencingArtifactToOxoG (Picard)     \u001b[36mExtract OxoG metrics from generalized artifacts metrics.  \u001b[0m\n",
      "\u001b[32m    CrosscheckFingerprints (Picard)              \u001b[36mChecks that all data in the input files appear to have come from the same individual\u001b[0m\n",
      "\u001b[32m    CrosscheckReadGroupFingerprints (Picard)     \u001b[36mDEPRECATED: USE CrosscheckFingerprints. Checks if all read groups appear to come from the same individual.\u001b[0m\n",
      "\u001b[32m    EstimateLibraryComplexity (Picard)           \u001b[36mEstimates the numbers of unique molecules in a sequencing library.  \u001b[0m\n",
      "\u001b[32m    EstimateLibraryComplexityGATK                \u001b[31m(BETA Tool) \u001b[36mEstimate library complexity from the sequence of read pairs\u001b[0m\n",
      "\u001b[32m    FlagStat                                     \u001b[36mAccumulate flag statistics given a BAM file\u001b[0m\n",
      "\u001b[32m    FlagStatSpark                                \u001b[31m(BETA Tool) \u001b[36mSpark tool to accumulate flag statistics\u001b[0m\n",
      "\u001b[32m    GetSampleName                                \u001b[31m(BETA Tool) \u001b[36mEmit a single sample name\u001b[0m\n",
      "\u001b[32m    MeanQualityByCycle (Picard)                  \u001b[36mCollect mean quality by cycle.\u001b[0m\n",
      "\u001b[32m    MeanQualityByCycleSpark                      \u001b[31m(BETA Tool) \u001b[36mMeanQualityByCycle on Spark\u001b[0m\n",
      "\u001b[32m    QualityScoreDistribution (Picard)            \u001b[36mChart the distribution of quality scores.  \u001b[0m\n",
      "\u001b[32m    QualityScoreDistributionSpark                \u001b[31m(BETA Tool) \u001b[36mQualityScoreDistribution on Spark\u001b[0m\n",
      "\u001b[32m    ValidateSamFile (Picard)                     \u001b[36mValidates a SAM or BAM file.\u001b[0m\n",
      "\u001b[32m    ViewSam (Picard)                             \u001b[36mPrints a SAM or BAM file to the screen\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mIntervals Manipulation:                          Tools that process genomic intervals in various formats\u001b[0m\n",
      "\u001b[32m    BedToIntervalList (Picard)                   \u001b[36mConverts a BED file to a Picard Interval List.  \u001b[0m\n",
      "\u001b[32m    IntervalListToBed (Picard)                   \u001b[36mConverts an Picard IntervalList file to a BED file.\u001b[0m\n",
      "\u001b[32m    IntervalListTools (Picard)                   \u001b[36mA tool for performing various IntervalList manipulations\u001b[0m\n",
      "\u001b[32m    LiftOverIntervalList (Picard)                \u001b[36mLifts over an interval list from one reference build to another. \u001b[0m\n",
      "\u001b[32m    PreprocessIntervals                          \u001b[31m(BETA Tool) \u001b[36mPrepares bins for coverage collection\u001b[0m\n",
      "\u001b[32m    SplitIntervals                               \u001b[36mSplit intervals into sub-interval files.\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mMetagenomics:                                    Tools that perform metagenomic analysis, e.g. microbial community composition and pathogen detection\u001b[0m\n",
      "\u001b[32m    PathSeqBuildKmers                            \u001b[36mBuilds set of host reference k-mers\u001b[0m\n",
      "\u001b[32m    PathSeqBuildReferenceTaxonomy                \u001b[36mBuilds a taxonomy datafile of the microbe reference\u001b[0m\n",
      "\u001b[32m    PathSeqBwaSpark                              \u001b[36mStep 2: Aligns reads to the microbe reference\u001b[0m\n",
      "\u001b[32m    PathSeqFilterSpark                           \u001b[36mStep 1: Filters low quality, low complexity, duplicate, and host reads\u001b[0m\n",
      "\u001b[32m    PathSeqPipelineSpark                         \u001b[36mCombined tool that performs all steps: read filtering, microbe reference alignment, and abundance scoring\u001b[0m\n",
      "\u001b[32m    PathSeqScoreSpark                            \u001b[36mStep 3: Classifies pathogen-aligned reads and generates abundance scores\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mOther:                                           Miscellaneous tools, e.g. those that aid in data streaming\u001b[0m\n",
      "\u001b[32m    CreateHadoopBamSplittingIndex                \u001b[31m(BETA Tool) \u001b[36mCreate a Hadoop BAM splitting index\u001b[0m\n",
      "\u001b[32m    FifoBuffer (Picard)                          \u001b[36mProvides a large, FIFO buffer that can be used to buffer input and output streams between programs.\u001b[0m\n",
      "\u001b[32m    GatherBQSRReports                            \u001b[36mGathers scattered BQSR recalibration reports into a single file\u001b[0m\n",
      "\u001b[32m    GatherTranches                               \u001b[31m(BETA Tool) \u001b[36mGathers scattered VQSLOD tranches into a single file\u001b[0m\n",
      "\u001b[32m    IndexFeatureFile                             \u001b[36mCreates an index for a feature file, e.g. VCF or BED file.\u001b[0m\n",
      "\u001b[32m    ParallelCopyGCSDirectoryIntoHDFSSpark        \u001b[31m(BETA Tool) \u001b[36mParallel copy a file or directory from Google Cloud Storage into the HDFS file system used by Spark\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mRead Data Manipulation:                          Tools that manipulate read data in SAM, BAM or CRAM format\u001b[0m\n",
      "\u001b[32m    AddCommentsToBam (Picard)                    \u001b[36mAdds comments to the header of a BAM file.\u001b[0m\n",
      "\u001b[32m    AddOrReplaceReadGroups (Picard)              \u001b[36mAssigns all the reads in a file to a single new read-group.\u001b[0m\n",
      "\u001b[32m    ApplyBQSR                                    \u001b[36mApply base quality score recalibration\u001b[0m\n",
      "\u001b[32m    ApplyBQSRSpark                               \u001b[31m(BETA Tool) \u001b[36mApply base quality score recalibration on Spark\u001b[0m\n",
      "\u001b[32m    BQSRPipelineSpark                            \u001b[31m(BETA Tool) \u001b[36mBoth steps of BQSR (BaseRecalibrator and ApplyBQSR) on Spark\u001b[0m\n",
      "\u001b[32m    BamToBfq (Picard)                            \u001b[36mConverts a BAM file into a BFQ (binary fastq formatted) file\u001b[0m\n",
      "\u001b[32m    BaseRecalibrator                             \u001b[36mGenerates recalibration table for Base Quality Score Recalibration (BQSR)\u001b[0m\n",
      "\u001b[32m    BaseRecalibratorSpark                        \u001b[31m(BETA Tool) \u001b[36mGenerate recalibration table for Base Quality Score Recalibration (BQSR) on Spark\u001b[0m\n",
      "\u001b[32m    BaseRecalibratorSparkSharded                 \u001b[31m(EXPERIMENTAL Tool) \u001b[36mBaseRecalibrator on Spark (experimental sharded implementation)\u001b[0m\n",
      "\u001b[32m    BuildBamIndex (Picard)                       \u001b[36mGenerates a BAM index \".bai\" file.  \u001b[0m\n",
      "\u001b[32m    BwaAndMarkDuplicatesPipelineSpark            \u001b[31m(BETA Tool) \u001b[36mTakes name-sorted file and runs BWA and MarkDuplicates.\u001b[0m\n",
      "\u001b[32m    BwaSpark                                     \u001b[31m(BETA Tool) \u001b[36mBWA on Spark\u001b[0m\n",
      "\u001b[32m    CleanSam (Picard)                            \u001b[36mCleans the provided SAM/BAM, soft-clipping beyond-end-of-reference alignments and setting MAPQ to 0 for unmapped reads\u001b[0m\n",
      "\u001b[32m    ClipReads                                    \u001b[36mClip reads in a SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    ConvertHeaderlessHadoopBamShardToBam         \u001b[31m(BETA Tool) \u001b[36mConvert a headerless BAM shard into a readable BAM\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m    DownsampleSam (Picard)                       \u001b[36mDownsample a SAM or BAM file.\u001b[0m\n",
      "\u001b[32m    ExtractOriginalAlignmentRecordsByNameSpark   \u001b[31m(BETA Tool) \u001b[36mSubsets reads by name\u001b[0m\n",
      "\u001b[32m    FastqToSam (Picard)                          \u001b[36mConverts a FASTQ file to an unaligned BAM or SAM file\u001b[0m\n",
      "\u001b[32m    FilterSamReads (Picard)                      \u001b[36mSubsets reads from a SAM or BAM file by applying one of several filters.\u001b[0m\n",
      "\u001b[32m    FixMateInformation (Picard)                  \u001b[36mVerify mate-pair information between mates and fix if needed.\u001b[0m\n",
      "\u001b[32m    FixMisencodedBaseQualityReads                \u001b[36mFix Illumina base quality scores in a SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    GatherBamFiles (Picard)                      \u001b[36mConcatenate efficiently BAM files that resulted from a scattered parallel analysis\u001b[0m\n",
      "\u001b[32m    LeftAlignIndels                              \u001b[36mLeft-aligns indels from reads in a SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    MarkDuplicates (Picard)                      \u001b[36mIdentifies duplicate reads.  \u001b[0m\n",
      "\u001b[32m    MarkDuplicatesGATK                           \u001b[31m(EXPERIMENTAL Tool) \u001b[36mExamines aligned records in the supplied SAM/BAM/CRAM file to locate duplicate molecules.\u001b[0m\n",
      "\u001b[32m    MarkDuplicatesSpark                          \u001b[31m(BETA Tool) \u001b[36mMarkDuplicates on Spark\u001b[0m\n",
      "\u001b[32m    MarkDuplicatesWithMateCigar (Picard)         \u001b[36mIdentifies duplicate reads, accounting for mate CIGAR.  \u001b[0m\n",
      "\u001b[32m    MergeBamAlignment (Picard)                   \u001b[36mMerge alignment data from a SAM or BAM with data in an unmapped BAM file.  \u001b[0m\n",
      "\u001b[32m    MergeSamFiles (Picard)                       \u001b[36mMerges multiple SAM and/or BAM files into a single file.  \u001b[0m\n",
      "\u001b[32m    PositionBasedDownsampleSam (Picard)          \u001b[36mDownsample a SAM or BAM file to retain a subset of the reads based on the reads location in each tile in the flowcell.\u001b[0m\n",
      "\u001b[32m    PrintReads                                   \u001b[36mPrint reads in the SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    PrintReadsSpark                              \u001b[31m(BETA Tool) \u001b[36mPrintReads on Spark\u001b[0m\n",
      "\u001b[32m    ReorderSam (Picard)                          \u001b[36mReorders reads in a SAM or BAM file to match ordering in a second reference file.\u001b[0m\n",
      "\u001b[32m    ReplaceSamHeader (Picard)                    \u001b[36mReplaces the SAMFileHeader in a SAM or BAM file.  \u001b[0m\n",
      "\u001b[32m    RevertBaseQualityScores                      \u001b[36mRevert Quality Scores in a SAM/BAM/CRAM file\u001b[0m\n",
      "\u001b[32m    RevertOriginalBaseQualitiesAndAddMateCigar (Picard)\u001b[36mReverts the original base qualities and adds the mate cigar tag to read-group BAMs\u001b[0m\n",
      "\u001b[32m    RevertSam (Picard)                           \u001b[36mReverts SAM or BAM files to a previous state.  \u001b[0m\n",
      "\u001b[32m    SamFormatConverter (Picard)                  \u001b[36mConvert a BAM file to a SAM file, or a SAM to a BAM\u001b[0m\n",
      "\u001b[32m    SamToFastq (Picard)                          \u001b[36mConverts a SAM or BAM file to FASTQ.\u001b[0m\n",
      "\u001b[32m    SetNmAndUqTags (Picard)                      \u001b[36mDEPRECATED: Use SetNmMdAndUqTags instead.\u001b[0m\n",
      "\u001b[32m    SetNmMdAndUqTags (Picard)                    \u001b[36mFixes the NM, MD, and UQ tags in a SAM file \u001b[0m\n",
      "\u001b[32m    SimpleMarkDuplicatesWithMateCigar (Picard)   \u001b[31m(BETA Tool) \u001b[36m(Experimental) Examines aligned records in the supplied SAM or BAM file to locate duplicate molecules.\u001b[0m\n",
      "\u001b[32m    SortSam (Picard)                             \u001b[36mSorts a SAM or BAM file\u001b[0m\n",
      "\u001b[32m    SortSamSpark                                 \u001b[31m(BETA Tool) \u001b[36mSortSam on Spark (works on SAM/BAM/CRAM)\u001b[0m\n",
      "\u001b[32m    SplitNCigarReads                             \u001b[36mSplit Reads with N in Cigar\u001b[0m\n",
      "\u001b[32m    SplitReads                                   \u001b[36mOutputs reads from a SAM/BAM/CRAM by read group, sample and library name\u001b[0m\n",
      "\u001b[32m    SplitSamByLibrary (Picard)                   \u001b[36mSplits a SAM or BAM file into individual files by library\u001b[0m\n",
      "\u001b[32m    SplitSamByNumberOfReads (Picard)             \u001b[36mSplits a SAM or BAM file to multiple BAMs.\u001b[0m\n",
      "\u001b[32m    UmiAwareMarkDuplicatesWithMateCigar (Picard) \u001b[31m(BETA Tool) \u001b[36mIdentifies duplicate reads using information from read positions and UMIs. \u001b[0m\n",
      "\u001b[32m    UnmarkDuplicates                             \u001b[36mClears the 0x400 duplicate SAM flag\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mReference:                                       Tools that analyze and manipulate FASTA format references\u001b[0m\n",
      "\u001b[32m    BaitDesigner (Picard)                        \u001b[36mDesigns oligonucleotide baits for hybrid selection reactions.\u001b[0m\n",
      "\u001b[32m    BwaMemIndexImageCreator                      \u001b[36mCreate a BWA-MEM index image file for use with GATK BWA tools\u001b[0m\n",
      "\u001b[32m    CreateSequenceDictionary (Picard)            \u001b[36mCreates a sequence dictionary for a reference sequence.  \u001b[0m\n",
      "\u001b[32m    ExtractSequences (Picard)                    \u001b[36mSubsets intervals from a reference sequence to a new FASTA file.\u001b[0m\n",
      "\u001b[32m    FindBadGenomicKmersSpark                     \u001b[31m(BETA Tool) \u001b[36mIdentifies sequences that occur at high frequency in a reference\u001b[0m\n",
      "\u001b[32m    NonNFastaSize (Picard)                       \u001b[36mCounts the number of non-N bases in a fasta file.\u001b[0m\n",
      "\u001b[32m    NormalizeFasta (Picard)                      \u001b[36mNormalizes lines of sequence in a FASTA file to be of the same length.\u001b[0m\n",
      "\u001b[32m    ScatterIntervalsByNs (Picard)                \u001b[36mWrites an interval list created by splitting a reference at Ns.\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mShort Variant Discovery:                         Tools that perform variant calling and genotyping for short variants (SNPs, SNVs and Indels)\u001b[0m\n",
      "\u001b[32m    CombineGVCFs                                 \u001b[36mMerges one or more HaplotypeCaller GVCF files into a single GVCF with appropriate annotations\u001b[0m\n",
      "\u001b[32m    GenomicsDBImport                             \u001b[36mImport VCFs to GenomicsDB\u001b[0m\n",
      "\u001b[32m    GenotypeGVCFs                                \u001b[36mPerform joint genotyping on one or more samples pre-called with HaplotypeCaller\u001b[0m\n",
      "\u001b[32m    HaplotypeCaller                              \u001b[36mCall germline SNPs and indels via local re-assembly of haplotypes\u001b[0m\n",
      "\u001b[32m    HaplotypeCallerSpark                         \u001b[31m(BETA Tool) \u001b[36mHaplotypeCaller on Spark\u001b[0m\n",
      "\u001b[32m    Mutect2                                      \u001b[36mCall somatic SNVs and indels via local assembly of haplotypes\u001b[0m\n",
      "\u001b[32m    ReadsPipelineSpark                           \u001b[31m(BETA Tool) \u001b[36mTakes unaligned or aligned reads and runs BWA (if specified), MarkDuplicates, BQSR, and HaplotypeCaller to generate a VCF file of variants\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mStructural Variant Discovery:                    Tools that detect structural variants        \u001b[0m\n",
      "\u001b[32m    DiscoverVariantsFromContigAlignmentsSAMSpark \u001b[31m(BETA Tool) \u001b[36m(Internal) Examines aligned contigs from local assemblies and calls structural variants\u001b[0m\n",
      "\u001b[32m    ExtractSVEvidenceSpark                       \u001b[31m(BETA Tool) \u001b[36m(Internal) Extracts evidence of structural variations from reads\u001b[0m\n",
      "\u001b[32m    FindBreakpointEvidenceSpark                  \u001b[31m(BETA Tool) \u001b[36m(Internal) Produces local assemblies of genomic regions that may harbor structural variants\u001b[0m\n",
      "\u001b[32m    StructuralVariationDiscoveryPipelineSpark    \u001b[31m(BETA Tool) \u001b[36mRuns the structural variation discovery workflow on a single sample\u001b[0m\n",
      "\u001b[32m    SvDiscoverFromLocalAssemblyContigAlignmentsSpark    \u001b[31m(BETA Tool) \u001b[36m(Internal) Examines aligned contigs from local assemblies and calls structural variants or their breakpoints\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mVariant Evaluation and Refinement:               Tools that evaluate and refine variant calls, e.g. with annotations not offered by the engine\u001b[0m\n",
      "\u001b[32m    AnnotatePairOrientation                      \u001b[31m(BETA Tool) \u001b[36m(EXPERIMENTAL) Annotate a non-M2 VCF (using the associated tumor bam) with pair orientation fields (e.g. F1R2 ).\u001b[0m\n",
      "\u001b[32m    AnnotateVcfWithBamDepth                      \u001b[36m(Internal) Annotate a vcf with a bam's read depth at each variant locus\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m    AnnotateVcfWithExpectedAlleleFraction        \u001b[36m(Internal) Annotate a vcf with expected allele fractions in pooled sequencing\u001b[0m\n",
      "\u001b[32m    CalculateGenotypePosteriors                  \u001b[36mCalculate genotype posterior probabilities given family and/or known population genotypes\u001b[0m\n",
      "\u001b[32m    CalculateMixingFractions                     \u001b[36m(Internal) Calculate proportions of different samples in a pooled bam\u001b[0m\n",
      "\u001b[32m    Concordance                                  \u001b[31m(BETA Tool) \u001b[36mEvaluate concordance of an input VCF against a validated truth VCF\u001b[0m\n",
      "\u001b[32m    CountFalsePositives                          \u001b[31m(BETA Tool) \u001b[36mCount PASS variants\u001b[0m\n",
      "\u001b[32m    CountVariants                                \u001b[36mCounts variant records in a VCF file, regardless of filter status.\u001b[0m\n",
      "\u001b[32m    CountVariantsSpark                           \u001b[31m(BETA Tool) \u001b[36mCountVariants on Spark\u001b[0m\n",
      "\u001b[32m    FindMendelianViolations (Picard)             \u001b[36mFinds mendelian violations of all types within a VCF\u001b[0m\n",
      "\u001b[32m    Funcotator                                   \u001b[31m(BETA Tool) \u001b[36mFunctional Annotator\u001b[0m\n",
      "\u001b[32m    GenotypeConcordance (Picard)                 \u001b[36mCalculates the concordance between genotype data of one samples in each of two VCFs - one  being considered the truth (or reference) the other being the call.  The concordance is broken into separate results sections for SNPs and indels.  Statistics are reported in three different files.\u001b[0m\n",
      "\u001b[32m    NeuralNetInference                           \u001b[31m(EXPERIMENTAL Tool) \u001b[36mApply 1d Convolutional Neural Net to filter annotated variants\u001b[0m\n",
      "\u001b[32m    ValidateBasicSomaticShortMutations           \u001b[31m(EXPERIMENTAL Tool) \u001b[36mCheck the variants in a VCF against a tumor-normal pair of bams representing the same samples, though not the ones from the actual calls.\u001b[0m\n",
      "\u001b[32m    ValidateVariants                             \u001b[36mValidate VCF\u001b[0m\n",
      "\u001b[32m    VariantsToTable                              \u001b[36mExtract fields from a VCF file to a tab-delimited table\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mVariant Filtering:                               Tools that filter variants by annotating the FILTER column\u001b[0m\n",
      "\u001b[32m    ApplyVQSR                                    \u001b[36m Apply a score cutoff to filter variants based on a recalibration table\u001b[0m\n",
      "\u001b[32m    CreateSomaticPanelOfNormals                  \u001b[31m(BETA Tool) \u001b[36mMake a panel of normals for use with Mutect2\u001b[0m\n",
      "\u001b[32m    FilterByOrientationBias                      \u001b[31m(EXPERIMENTAL Tool) \u001b[36mFilter Mutect2 somatic variant calls using orientation bias\u001b[0m\n",
      "\u001b[32m    FilterMutectCalls                            \u001b[36mFilter somatic SNVs and indels called by Mutect2\u001b[0m\n",
      "\u001b[32m    FilterVcf (Picard)                           \u001b[36mHard filters a VCF.\u001b[0m\n",
      "\u001b[32m    VariantFiltration                            \u001b[36mFilter variant calls based on INFO and/or FORMAT annotations\u001b[0m\n",
      "\u001b[32m    VariantRecalibrator                          \u001b[36mBuild a recalibration model to score variant quality for filtering purposes\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\u001b[31mVariant Manipulation:                            Tools that manipulate variant call format (VCF) data\u001b[0m\n",
      "\u001b[32m    FixVcfHeader (Picard)                        \u001b[36mReplaces or fixes a VCF header.\u001b[0m\n",
      "\u001b[32m    GatherVcfs (Picard)                          \u001b[36mGathers multiple VCF files from a scatter operation into a single VCF file\u001b[0m\n",
      "\u001b[32m    GatherVcfsCloud                              \u001b[31m(BETA Tool) \u001b[36mGathers multiple VCF files from a scatter operation into a single VCF file\u001b[0m\n",
      "\u001b[32m    LiftoverVcf (Picard)                         \u001b[36mLifts over a VCF file from one reference build to another.  \u001b[0m\n",
      "\u001b[32m    MakeSitesOnlyVcf (Picard)                    \u001b[36mCreates a VCF that contains all the site-level information for all records in the input VCF but no genotype information.\u001b[0m\n",
      "\u001b[32m    MergeVcfs (Picard)                           \u001b[36mCombines multiple variant files into a single variant file\u001b[0m\n",
      "\u001b[32m    PrintVariantsSpark                           \u001b[31m(BETA Tool) \u001b[36mPrints out variants from the input VCF.\u001b[0m\n",
      "\u001b[32m    RemoveNearbyIndels                           \u001b[36m(Internal) Remove indels from the VCF file that are close to each other.\u001b[0m\n",
      "\u001b[32m    RenameSampleInVcf (Picard)                   \u001b[36mRenames a sample within a VCF or BCF.\u001b[0m\n",
      "\u001b[32m    SelectVariants                               \u001b[36mSelect a subset of variants from a VCF file\u001b[0m\n",
      "\u001b[32m    SortVcf (Picard)                             \u001b[36mSorts one or more VCF files.  \u001b[0m\n",
      "\u001b[32m    SplitVcfs (Picard)                           \u001b[36mSplits SNPs and INDELs into separate files.  \u001b[0m\n",
      "\u001b[32m    UpdateVCFSequenceDictionary                  \u001b[36mUpdates the sequence dictionary in a variant file.\u001b[0m\n",
      "\u001b[32m    UpdateVcfSequenceDictionary (Picard)         \u001b[36mTakes a VCF and a second file that contains a sequence dictionary and updates the VCF with the new sequence dictionary.\u001b[0m\n",
      "\u001b[32m    VariantAnnotator                             \u001b[31m(BETA Tool) \u001b[36mTool for adding annotations to VCF files\u001b[0m\n",
      "\u001b[32m    VcfFormatConverter (Picard)                  \u001b[36mConverts VCF to BCF or BCF to VCF.  \u001b[0m\n",
      "\u001b[32m    VcfToIntervalList (Picard)                   \u001b[36mConverts a VCF or BCF file to a Picard Interval List\u001b[0m\n",
      "\n",
      "\u001b[37m--------------------------------------------------------------------------------------\n",
      "\u001b[0m\n",
      "***********************************************************************\n",
      "\n",
      "A USER ERROR has occurred: 'Print' is not a valid command.\n",
      "Did you mean one of these?\n",
      "        PrintReads        PrintVariantsSpark        PrintReadsSpark\n",
      "\n",
      "***********************************************************************\n",
      "Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing script in docker returns an error (exitcode=2).\n",
      "The script has been saved to /Users/bpeng1/sos/sos-docs/src/tutorials/.sos/docker_run_30258.sh. To reproduce the error please run:\n",
      "``docker run --rm   -v /Users:/Users -v /tmp:/tmp -v /Users/bpeng1/sos/sos-docs/src/tutorials/.sos/docker_run_30258.sh:/var/lib/sos/docker_run_30258.sh    -t -P -w=/Users/bpeng1/sos/sos-docs/src/tutorials -u 1985961928:895809667    dceoy/gatk  Print Reads -h\n",
      "``\n"
     ]
    }
   ],
   "source": [
    "script: args = '{script}', docker_image = 'dceoy/gatk'\n",
    "  Print Reads -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations\n",
    "\n",
    "* Virtual Box virtual machine does not support symbolic link so running `ln -s` inside a docker machine under Mac will cause a strange error message `Read-only file system`.\n",
    "* Killing a sos task or sos process will not terminate scripts that are executed by the docker daemon."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "sos": {
   "default_kernel": "SoS",
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0,
    "style": "side"
   },
   "version": "0.9.14.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
